{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ba6dae",
   "metadata": {},
   "source": [
    "# Glucose Level Prediction DataQUEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794aa730",
   "metadata": {},
   "source": [
    "## Loading of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497d79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d924ee",
   "metadata": {},
   "source": [
    "## Implementation of Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79452d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7878787878787878\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 198 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# split dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "valra= 17\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=valra)\n",
    "\n",
    "# create Random Forest classifier object\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=valra)\n",
    "\n",
    "# train the model using the training sets\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# calculate accuracy score of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99c1fc",
   "metadata": {},
   "source": [
    "## Implementation of Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27167c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7359307359307359\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 8.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# split dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "##Golden value\n",
    "valra= 32\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=valra)\n",
    "\n",
    "# create Decision Tree classifier object\n",
    "dtc = DecisionTreeClassifier(random_state=valra)\n",
    "\n",
    "# train the model using the training sets\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "\n",
    "# calculate accuracy score of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cce691",
   "metadata": {},
   "source": [
    "## Implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e67395bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[121  30]\n",
      " [ 30  50]]\n",
      "F1 Score: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yahya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "# split dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create logistic regression object\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions using the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate confusion matrix and F1 Score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n",
    "print('F1 Score: {:.2f}'.format(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383c6c6",
   "metadata": {},
   "source": [
    "## Implementation Of Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f91ace83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.18\n",
      "R-squared: 0.22\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 8.76 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "# split dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create linear regression object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# train the model using the training sets\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions using the testing set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# calculate mean squared error and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print('Mean squared error: {:.2f}'.format(mse))\n",
    "print('R-squared: {:.2f}'.format(r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d18c43",
   "metadata": {},
   "source": [
    "## Implementation of Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5b9de63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.19\n",
      "R-squared: 0.15\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 75.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "# split dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create SVR object with RBF kernel\n",
    "svr = SVR(kernel='rbf')\n",
    "\n",
    "# train the model using the training sets\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions using the testing set\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# calculate mean squared error and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print('Mean squared error: {:.2f}'.format(mse))\n",
    "print('R-squared: {:.2f}'.format(r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fcd02",
   "metadata": {},
   "source": [
    "## Implementation of Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0c4ff418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.17\n",
      "R-squared: 0.24\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 60 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "# split dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create Gradient Boosting Regression object\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=42)\n",
    "\n",
    "# train the model using the training sets\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions using the testing set\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "# calculate mean squared error and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print('Mean squared error: {:.2f}'.format(mse))\n",
    "print('R-squared: {:.2f}'.format(r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3a6b9",
   "metadata": {},
   "source": [
    "## Implementation of Neural Network Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09a465a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.37\n",
      "R-squared: -0.63\n",
      "CPU times: total: 3.19 s\n",
      "Wall time: 542 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "# split dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create MLPRegressor object\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,50), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "# train the model using the training sets\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# make predictions using the testing set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# calculate mean squared error and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print('Mean squared error: {:.2f}'.format(mse))\n",
    "print('R-squared: {:.2f}'.format(r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724807d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(np\u001B[38;5;241m.\u001B[39mmean(results))\n",
      "\u001B[0;31mTypeError\u001B[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "results = np.array[0,1,2]\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
